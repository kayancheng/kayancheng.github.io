{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: Review: Descriptive Statistics & Basic Python Coding (Empty Version)\n",
    "<img src=\"DescriptiveStat.jpg\" alt=\"Descriptive Statistics\" width=\"80%\">\n",
    "\n",
    "**Overview**\n",
    "\n",
    " You should be comfortable with basic Python coding and descriptive statistics. In this lecture, we will review these skills and apply them to synthetic data in econometrics contexts.\n",
    "\n",
    "**In this lecture, we will:**\n",
    "- Refresh core Python skills in data preprocessing (variables, lists, functions).\n",
    "\n",
    "- Compute descriptive statistics (mean, median, variance, correlation).\n",
    "\n",
    "- Visualize distributions and relationships (histogram, scatterplot).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e143590",
   "metadata": {},
   "source": [
    "## Part A â€” Before Coding... Let's Think! ðŸ§ \n",
    "\n",
    "Before we start writing Python code, letâ€™s **understand the basics** behind descriptive statistics.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda72b3",
   "metadata": {},
   "source": [
    "### A1. What is Descriptive Statistics?\n",
    "\n",
    "Descriptive statistics are **numbers** (or a **set of numbers**) that **summarize and describe** the main features of a dataset.  \n",
    "\n",
    "Think of them as a **quick snapshot** of your data â€” they **tell the story** before we dive into deeper analysis.\n",
    "\n",
    "**Some key aspects:**\n",
    "\n",
    "- **Central Tendency** â†’ Where the data is centered â†’ *(e.g. mean, median, mode)*\n",
    "- **Dispersion** â†’ How spread out the data is â†’ *(e.g. variance, standard deviation, range)*\n",
    "- **Relationships** â†’ How variables move together â†’ *(e.g. correlation, covariance)*\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6953e2c0",
   "metadata": {},
   "source": [
    "### A2. Why Are Descriptive Statistics Important?\n",
    "\n",
    "Descriptive statistics are **always the first step** in data analysis because they help you:\n",
    "\n",
    "- Understand the **basic patterns** in your data.\n",
    "- Detect **outliers, anomalies, or missing values**.\n",
    "- See the **overall shape** of your dataset.\n",
    "- Prepare for deeper **statistical analysis and modeling**.\n",
    "\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957771e",
   "metadata": {},
   "source": [
    "ðŸ“º\n",
    "[Prof. Bing Wen Brunton - Asking and Answering Questions with Data through Plots](https://www.youtube.com/watch?v=b_TIPozKAcg)\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65020141",
   "metadata": {},
   "source": [
    "\n",
    "### **Key Takeaway** âœ…  \n",
    "Before estimating regressions or running econometric models,  **start with descriptive statistics** â€” they give you the **foundation** for better insights.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058bc125",
   "metadata": {},
   "source": [
    "## Part B -  Now, Let's code!\n",
    "In today's lab, we will start by warming up with some basic Python coding skills. \n",
    "\n",
    "Then, we will create a synthetic dataset that mimics real-world economic data. \n",
    "\n",
    "Finally, we will compute and visualize descriptive statistics to understand the data better.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3f9d7",
   "metadata": {},
   "source": [
    "### Part B1 - Warming up: Basic Python Coding Refresher "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01112020",
   "metadata": {},
   "source": [
    "#### **1. Variables & Data Types**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data types in Python\n",
    "x =           # Integer: whole number\n",
    "y =         # Float: decimal number\n",
    "name =   # String: text\n",
    "is_a_good_student =   # Boolean: True or False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63924ad5",
   "metadata": {},
   "source": [
    "#### **2. Lists & Indexing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16281f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists: **ordered** collections of items\n",
    "\n",
    "numbers =   # Create a list, and assign it to a variable (called `numbers` in this case)\n",
    "first_number =   # Access first element **Using 0-based indexing**\n",
    "\n",
    "\n",
    "# Do some list operations\n",
    "          # Add an element to the end of the list\n",
    "print(\"The list now is:\", numbers)\n",
    "          # Remove an element from the list\n",
    "# print(\"The list now is:\", numbers)\n",
    "          # Modify an element in the list \n",
    "# print(\"The list now is:\", numbers)\n",
    "\n",
    "# Note that after **each** operation, the content of the list `numbers` changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c4d108",
   "metadata": {},
   "source": [
    "#### **3. Functions** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions: reusable blocks of code that perform a specific task\n",
    "\n",
    "# Define the function\n",
    "def add(a, b):\n",
    "    return a - b\n",
    "\n",
    "# Call the function and store the result\n",
    "\n",
    "\n",
    "# Is it really 8? Let's print it out to check!\n",
    "print(\"The result is:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7051fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oops! The function is supposed to add two numbers, but it subtracts them instead. Let's fix it.\n",
    "\n",
    "\n",
    "# Call the function again and store the result\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(\"The result is:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b38bd7c",
   "metadata": {},
   "source": [
    "#### **4. If Statements & Loops**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997fa3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Flow: if-elif-else statements\n",
    "\n",
    "# Try different nymbers here\n",
    "test_score = 100\n",
    "#test_score = 85\n",
    "#test_score = 45\n",
    "\n",
    "# if-elif-else statement (Disclaimer: this is just an example, not a real grading scheme of this class :P)\n",
    "\n",
    "\n",
    "print(\"The grade is:\", grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355e2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Flow: For loops\n",
    "\n",
    "for_loop_go_through_list = [1, 2, 3, 4, 5]  # A list to demonstrate for loop\n",
    "\n",
    " # Print each number in the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8908c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Flow: While loops\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ccd73",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dotted #bbb;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7fcc8f",
   "metadata": {},
   "source": [
    "### Part B2 - Descriptive Statistics of Synthetic Data in Econometrics Contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebf8b9",
   "metadata": {},
   "source": [
    "#### **Step 0: ðŸ“¦ Let's Install the Required Libraries Together**\n",
    "\n",
    "We will use four main Python libraries in this lecture:  **NumPy**, **Pandas**, **Matplotlib**, and **Seaborn**.\n",
    "\n",
    "> ðŸ’¡ **Tip:** In Jupyter notebooks, use **`%pip`** instead of `pip` to install packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's install and import the required libraries together!\n",
    "%pip install numpy pandas matplotlib seaborn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a620da",
   "metadata": {},
   "source": [
    "#### **Step 1: Create a Synthetic Econometrics-Style Dataset**\n",
    "\n",
    "Let's generate a synthetic dataset for **n = 500 individuals**.  \n",
    "It will include:\n",
    "\n",
    "- **Schooling years** â†’ Number of years of education (8â€“20 years).\n",
    "- **Work experience** â†’ Years of potential labor market experience (0â€“40 years).\n",
    "- **Annual earnings** â†’ Simulated based on schooling, experience, and some random variation.\n",
    "\n",
    "We also make the dataset slightly more **realistic** by:\n",
    "- Introducing a few **missing values** in schooling.\n",
    "- Adding a few **high-income outliers**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07333116",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# **************** You don't need to modify anything in this cell.*****************\n",
    "# **************** Just run it to generate the dataset. *****************\n",
    "\n",
    "# In this example, we create a simulated dataset for 500 individuals.\n",
    "# The dataset includes schooling years, work experience, and annual earnings.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "rng = np.random.default_rng(42)\n",
    "n = 500  # sample size\n",
    "\n",
    "# 1) Schooling years: 8â€“20 years, slightly right-skewed\n",
    "schooling = np.clip(np.round(rng.normal(14, 2.2, n)), 8, 20)\n",
    "\n",
    "# 2) Work experience: 0â€“40 years\n",
    "#    More schooling â†’ slightly less experience on average\n",
    "experience = np.clip(np.round(rng.normal(18 - 0.6*(schooling - 12), 6, n)), 0, 40)\n",
    "\n",
    "# 3) Earnings (annual income)\n",
    "#    Based on a wage equation with schooling, experience, and diminishing returns\n",
    "beta0 = 2.0       # intercept\n",
    "beta_s = 0.09     # ~9% return per extra year of schooling\n",
    "beta_x = 0.03     # experience effect\n",
    "beta_x2 = -0.0006 # diminishing returns to experience\n",
    "\n",
    "# Generate earnings in levels\n",
    "epsilon = rng.normal(0, 0.25, n)\n",
    "log_earn = beta0 + beta_s*schooling + beta_x*experience + beta_x2*(experience**2) + epsilon\n",
    "earn = np.exp(log_earn)  # convert from log scale to positive earnings\n",
    "\n",
    "# 4) Add a few missing values and high-income outliers for realism\n",
    "schooling[rng.choice(n, 6, replace=False)] = np.nan\n",
    "earn[rng.choice(n, 5, replace=False)] *= 4  # very high earners\n",
    "\n",
    "# 5) Create DataFrame (final dataset)\n",
    "df = pd.DataFrame({\n",
    "    'earn': earn,\n",
    "    'schooling': schooling,\n",
    "    'experience': experience\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b71c8",
   "metadata": {},
   "source": [
    "#### **Step 2: Take a Look at the Dataset**\n",
    "Imagine you are an economist who just received this dataset. First thing you want to do is to understand its structure and contents.\n",
    "\n",
    "One way to do this is to preview the first few rows of the dataset. It helps you get a quick sense of what the data looks like:\n",
    "- What variables are included?\n",
    "- What are their data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193bd6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first three rows of the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cd03bc",
   "metadata": {},
   "source": [
    "#### **Step 3: Descriptive Statistics**\n",
    "Fast profiling to understand characteristics of the data.\n",
    "\n",
    "Recall different types of descriptive statistics:\n",
    "- Central Tendency: Mean, Median, Mode\n",
    "- Dispersion: Variance, Standard Deviation, Range\n",
    "- Relationships: Correlation, Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf4046",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compute the descriptive statistics\n",
    "# ``df.describe`` is a very useful function from pandas to get a quick overview of the dataset.\n",
    "# It provides count, mean, std, min, 25%, 50%, 75%, and max for each numerical column\n",
    "# The include='all' argument ensures that it includes all columns, even if they are not numerical\n",
    "# The .T at the end transposes the result for better readability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d2102",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Q: Is the output of df.describe() correct? Let's compute them one by one to check.\n",
    "# This is to verify that we understand what each statistic means.\n",
    "\n",
    "# As an example, let's compute the mean of the 'earn' column manually.\n",
    "# Recall: mean = sum of all values / number of values\n",
    "\n",
    "\n",
    "\n",
    "# Check if they are the same\n",
    "print(\"Mean (manual):\", mean_earn_manual)\n",
    "print(\"Mean (function):\", mean_earn_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144892d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, we can compute all the statistics for the 'earn' column\n",
    "min_earn = df['earn'].min()\n",
    "mean_earn = df['earn'].mean()\n",
    "median_earn = df['earn'].median()\n",
    "std_earn = df['earn'].std()\n",
    "var_earn = df['earn'].var()\n",
    "max_earn = df['earn'].max()\n",
    "range_earn = max_earn - min_earn\n",
    "\n",
    "print(\"Mean:\", mean_earn)\n",
    "print(\"Median:\", median_earn)\n",
    "print(\"Standard Deviation:\", std_earn)\n",
    "print(\"Variance:\", var_earn)\n",
    "print(\"Minimum:\", min_earn)\n",
    "print(\"Maximum:\", max_earn)\n",
    "print(\"Range:\", range_earn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdbac20",
   "metadata": {},
   "source": [
    "It verifies the output of `df.describe()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241cee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another interesting statistic to look at could be the mean earnings by schooling years.\n",
    "\n",
    "# Compute the mean by schooling years\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9930967",
   "metadata": {},
   "source": [
    "#### **Step 4: Visualizing Distributions via Histograms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae6890",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Histogram of the 'earn' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['earn'], bins=30, kde=True)\n",
    "plt.title('Distribution of Annual Earnings')\n",
    "plt.xlabel('Annual Earnings')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 200000)  # Limit x-axis for better visualization\n",
    "plt.show()\n",
    "\n",
    "# Oops! Nothing showed up. Why?\n",
    "# Hint: Think about the range of earnings and the default x-axis limits of the plot.\n",
    "# Solution: We can set the x-axis limits to focus on the main distribution and exclude extreme outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd293f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try running the histogram code again with the xlim line included.\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['earn'], bins=30, kde=True)\n",
    "plt.title('Distribution of Annual Earnings')\n",
    "plt.xlabel('Annual Earnings')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Change  Limit x-axis for better visualization\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f35e2",
   "metadata": {},
   "source": [
    "#### **Step 5: Visualizing Relationships via Scatterplots**\n",
    "\n",
    "It makes intuitive sense to expect a positive relationship between schooling and earnings, let's try to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f529e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Scatter plot of schooling vs earn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='schooling', y='earn', data=df, alpha=0.6)\n",
    "plt.title('Schooling vs Annual Earnings')\n",
    "plt.xlabel('Years of Schooling')\n",
    "plt.ylabel('Annual Earnings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b4b16",
   "metadata": {},
   "source": [
    "#### **Step 4: Data Hygiene: Missing Values**\n",
    "- Data is not always perfect. It is common to encounter, for example, **missing values**.\n",
    "- Detecting and handling missing values is crucial for accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d27ab5",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Detcting missing values:\n",
    "print(\"Missing values per column:\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "\n",
    "# Here, we will demonstrate two common methods to handle missing values:\n",
    "# a) Dropping rows with missing values\n",
    "# b) Simple imputation (filling missing values with the median)\n",
    "\n",
    "# a) Dropping rows with missing values\n",
    "df_dropped = \n",
    "print(\"After dropping rows with missing 'schooling':\")\n",
    "print(df_dropped.isna().sum(), \"\\n\")\n",
    "print(\"Number of rows before:\", len(df))\n",
    "print(\"Number of rows after:\", len(df_dropped), \"\\n\")\n",
    "\n",
    "# b) Simple imputation for 'schooling' using the median\n",
    "df['schooling_imputed'] = \n",
    "print(\"After imputing missing 'schooling' with median:\")\n",
    "print(df.isna().sum(), \"\\n\")\n",
    "print(\"Number of rows remains the same:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5f0c0",
   "metadata": {},
   "source": [
    "> **ðŸ’¡Note:**  \n",
    "> It is important to think about **why data might be missing**.  \n",
    "> - Is it **completely random**, or does it **follow a pattern**?  \n",
    "> â†’ This can **affect how you handle missing values** and the reliability of your analysis.\n",
    "\n",
    "**For example:**\n",
    "- If a few `schooling` values are missing **completely at random** (e.g., students forgot to answer the survey),\n",
    "\n",
    "  â†’ You might safely **fill them with the median** or **drop those rows**.\n",
    "\n",
    "- But if `schooling` is **missing mostly for very high earners** who refused to report their education,  \n",
    "\n",
    "  â†’ Simply dropping or imputing values could **bias your results**, especially if you're studying the relationship between schooling and earnings.\n",
    "\n",
    "Understanding **why** data is missing helps you choose the **right strategy**:\n",
    "\n",
    "- **Drop** the missing rows if they are few and random.\n",
    "\n",
    "- **Impute** when patterns are small but predictable.\n",
    "\n",
    "- **Investigate deeper** if missingness is related to key outcomes â€” sometimes, more careful handling is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c496f8",
   "metadata": {},
   "source": [
    "> âš ï¸ **Important Reminder**  \n",
    "> Always be **transparent** about **how** you handle missing data **and why** you chose that approach.  \n",
    "> Clearly document:\n",
    "> - What method you used (e.g., drop, impute).\n",
    "> - The reason for your choice.\n",
    "> - The potential **impact** on your analysis and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84587ede",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dotted #bbb;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc05a5c",
   "metadata": {},
   "source": [
    "### **Key Takeaways** âœ…  \n",
    "\n",
    "- Descriptive statistics are your first step in understanding data.\n",
    "\n",
    "    - They provide insights into the data's structure, central tendencies, variability, and relationships between variables. \n",
    "\n",
    "    - Always start with descriptive statistics before diving into complex analyses.\n",
    "\n",
    "- It is important to keep in mind that:\n",
    "\n",
    "    - The above steps are iterative and **not strictly linear**. **You may need to revisit earlier steps as you uncover new insights or issues in the data.**\n",
    "    \n",
    "    - Also, there is **not only one way to do descriptive statistics.** Feel free to explore other methods and visualizations that suit your data and research questions!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45fdb44",
   "metadata": {},
   "source": [
    "## References & Acknowledgments\n",
    "\n",
    "- This teaching material was prepared with the assistance of **OpenAI's ChatGPT (GPT-5)**.\n",
    "\n",
    "- Cover Image: *Data Wrangling â€” From Messy to Clean* by **ChrisJen517**. Licensed under **CC BY-SA 4.0** (2020). Retrieved from [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Data_Wrangling_From_Messy_To_Clean_Data_Management.jpg).\n",
    "\n",
    "- Video Resource: *Asking and Answering Questions with Data through Plots* by [Prof. Bing Wen Brunton](https://www.biology.washington.edu/people/profile/bing-w-brunton). Retrieved from [YouTube](https://www.youtube.com/watch?v=b_TIPozKAcg).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ae299f",
   "metadata": {},
   "source": [
    "## Extra reading (Optional)\n",
    "For students who want to learn more about Python coding style and best practices, here is a useful resource:\n",
    "- PEP8 - Style Guide for Python Code: [PEP 8](https://peps.python.org/pep-0008/)\n",
    "\n",
    "Good writing practice is important for collaboration, code review, and future reference!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of lecture notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d75d1e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
