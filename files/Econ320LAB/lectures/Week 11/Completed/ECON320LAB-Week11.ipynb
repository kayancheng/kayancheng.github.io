{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f78eec2",
   "metadata": {},
   "source": [
    "# Week 11: Critical Thinking & Causal Inference ‚Äì Endogeneity & Instrumental Variables (IV)\n",
    "\n",
    "# (Completed version)\n",
    "\n",
    "This week is about a very common real‚Äëworld situation:\n",
    "\n",
    "> We want the effect of **education** on **earnings**, but we can't run a perfect experiment and we can't observe all the things that make some people both **study more** and **earn more**.\n",
    "\n",
    "Ordinary least squares (OLS) then mixes up:\n",
    "\n",
    "- the **true causal effect** of schooling on earnings, and  \n",
    "\n",
    "- the effect of **unobserved factors** like ability, motivation, or family background.\n",
    "\n",
    "**Instrumental variables (IV)** give us a clever workaround. Instead of trying to perfectly measure all confounders, we look for a variable that _nudges_ education up or down **for reasons unrelated to those confounders**.\n",
    "\n",
    "In this lecture and lab we‚Äôll use the classic example:\n",
    "\n",
    "- **Outcome**: earnings  \n",
    "\n",
    "- **Treatment**: years of education  \n",
    "\n",
    "- **Instrument**: distance to the nearest college when you were a teenager\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f722ed64",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "\n",
    "By the end of this week you should be able to:\n",
    "\n",
    "- Explain, in words and pictures, why OLS can be biased when important confounders are unobserved.  \n",
    "\n",
    "- State and interpret the three core IV assumptions:  \n",
    "\n",
    "  - **Relevance** (the instrument actually moves the treatment),  \n",
    "\n",
    "  - **Independence** (as good as randomly assigned, conditional on controls),  \n",
    "\n",
    "  - **Exclusion restriction** (it affects the outcome **only** through the treatment).  \n",
    "\n",
    "- Read and explain an IV DAG using the education‚Äìearnings example.  \n",
    "\n",
    "- Describe the intuition behind two‚Äëstage least squares (2SLS):  \n",
    "\n",
    "  - ‚ÄúFirst stage‚Äù: use the instrument to isolate the part of education that is as‚Äëgood‚Äëas‚Äërandom.  \n",
    "  \n",
    "  - ‚ÄúSecond stage‚Äù: use only that part to estimate the causal effect on earnings.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16583b",
   "metadata": {},
   "source": [
    "## 1. Motivation: education and earnings\n",
    "\n",
    "We care about the causal question:\n",
    "\n",
    "> **If a person gets one extra year of schooling, how much do their earnings change on average?**\n",
    "\n",
    "Let\n",
    "\n",
    "- $X$ = years of education  \n",
    "- $Y$ = earnings (e.g. log wages)  \n",
    "- $U$ = ‚Äúeverything else‚Äù that affects both $X$ and $Y$  \n",
    "  - e.g. ability, grit, family support, neighborhood, school quality, etc.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "If we run a simple OLS regression\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X + \\varepsilon,\n",
    "$$\n",
    "the slope $\\beta_1$ will usually be **too big** or **too small**, because $X$ is positively or negatively related to $U$.\n",
    "\n",
    "- Students with **high ability / strong families** might both **study more** and **earn more** ‚Üí OLS overstates the causal effect.  \n",
    "- In some settings, people who stay longer in school might be those with **fewer good outside options** ‚Üí OLS could understate the effect.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "The key problem is:\n",
    "\n",
    "> **We cannot see $U$, but $U$ affects both $X$ and $Y$.**  \n",
    "> This is the classic **endogeneity** / **omitted variable bias** problem.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f624d0b",
   "metadata": {},
   "source": [
    "## Recap: Omitted Variable Bias (OVB) and the ‚Äúideal fix‚Äù\n",
    "\n",
    "From the **OVB lecture**, you already know the basic story:\n",
    "\n",
    "- If there is a variable that affects both **education** and **earnings**  and we **observe** it, the fix is simple: **include it as a control**.\n",
    "\n",
    "In an ideal world our wage equation would be\n",
    "\n",
    "$$\n",
    "\\text{wage} = \\beta_0 + \\beta_1 \\text{educ} + \\beta_2 \\text{ability} + u.\n",
    "$$\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "If we observed ‚Äútrue ability‚Äù we would just put it in the regression and OLS would not be biased by ability.\n",
    "\n",
    "But in reality, things like **true ability, motivation, family background** are often\n",
    "- hard to measure well, or  \n",
    "- completely unobserved.\n",
    "\n",
    "Then they get absorbed into the error term, and since ability is correlated with education, we get\n",
    "\n",
    "$$\n",
    "\\text{Corr}(\\text{educ}, \\varepsilon) \\neq 0,\n",
    "$$\n",
    "\n",
    "which is exactly **endogeneity** (a regressor correlated with the error).  \n",
    "\n",
    "So you can think of ‚Äúunobserved OVB‚Äù as one of the main ways endogeneity shows up.\n",
    "\n",
    "\n",
    "> Takeaway üí°\n",
    ">\n",
    "> - If we could measure ability well, the OVB lecture already told us what to do:  \n",
    "> just add it as a control and we‚Äôre fine.  \n",
    ">\n",
    "> - But for things like true ability or family background, we **can‚Äôt** measure them well.  \n",
    "> -> That‚Äôs exactly when OLS breaks, and we need a different trick ‚Äî **instrumental variables**.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4b77c",
   "metadata": {},
   "source": [
    "## 2. IV example and directed acyclic graph (DAG): distance to college\n",
    "\n",
    "To deal with unobserved confounders, we look for an **instrument** $Z$.  \n",
    "\n",
    "In our example, a natural candidate is:\n",
    "\n",
    "- $Z$: distance to the nearest college when the individual was a teenager\n",
    "\n",
    "> Intuition:\n",
    ">\n",
    "> - If you grow up **closer to a college**, it's **cheaper and easier** to attend.  \n",
    "> - So $Z$ should **push education $X$ up or down**, even for people who are otherwise similar.  \n",
    "> - But, after controlling for broad region, **living a bit closer or farther from a college should not directly change your earnings** except through education.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "We will think in terms of four variables:\n",
    "\n",
    "- $Z$: distance to college (instrument)  \n",
    "- $X$: education (endogenous treatment)  \n",
    "- $Y$: earnings (outcome)  \n",
    "- $U$: unobserved ability and family background (confounders)\n",
    "\n",
    "The DAG below summarizes this story graphically.\n",
    " - Solid arrows = allowed causal paths.  \n",
    " - Dashed arrow = ‚Äúforbidden‚Äù direct effect that IV **rules out** (and the X on it reminds us of that).\n",
    "\n",
    "<img src=\"iv_dag_education_example.png\" alt=\"IV DAG: Distance to College as Instrument\" width=\"100%\">\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57406980",
   "metadata": {},
   "source": [
    "## 3. IV assumptions in the DAG (with intuition)\n",
    "\n",
    "From the DAG, we can read off three key assumptions. You should be able to explain each one **in words**.\n",
    "\n",
    "### 3.1. Relevance: $Z$ really moves $X$\n",
    "\n",
    "- Graphically: **solid arrow** $Z \\to X$.  \n",
    "- People who grow up closer to a college are **more likely to get more education**.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "### 3.2 Independence: $Z$ is ‚Äúas‚Äëgood‚Äëas‚Äërandom‚Äù w.r.t. $U$\n",
    "\n",
    "- Graphically: **no arrow** between $Z$ and $U$.  \n",
    "- In words: conditional on simple controls (region, urban/rural, etc.), distance to college is **not systematically related** to unobserved ability or family background.\n",
    "\n",
    "> This is a **research design judgment call**: we argue that, after controls, families did not choose location in a way that‚Äôs tightly tied to their child‚Äôs unobserved ability.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "### 3.3 Exclusion restriction: $Z$ affects $Y$ only through $X$\n",
    "\n",
    "- Graphically: the **dashed arrow** $Z \\to Y$ is **crossed out**.  \n",
    "- Distance to college has **no direct effect** on earnings except through its effect on education.\n",
    "\n",
    "This rules out channels like ‚Äúlocal wages are higher near colleges, even for equally educated workers‚Äù or ‚Äújob networks from growing up near a campus, regardless of whether you attend‚Äù. If those effects are large, the instrument is not valid.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca8ba28",
   "metadata": {},
   "source": [
    "## 4. Two-stage least squares (2SLS) ‚Äì intuition first\n",
    "\n",
    "IV/2SLS is basically a **two‚Äëstep filtering process**:\n",
    "\n",
    "1. **Step 1: isolate the part of $X$ that comes from the instrument.**  \n",
    "   We use $Z$ (and controls $W$) to predict education:\n",
    "   $$\n",
    "   X_i = \\pi_0 + \\pi_1 Z_i + \\pi_2 W_i + v_i.\n",
    "   $$\n",
    "   The fitted values $\\hat X_i$ are the part of education that is ‚Äúexplained by‚Äù distance to college and the controls.  \n",
    "   Intuition: this is the **as‚Äëgood‚Äëas‚Äërandom variation** in schooling.\n",
    "\n",
    "2. **Step 2: see how outcomes move with this ‚Äúclean‚Äù part of $X$.**  \n",
    "   We then regress earnings on the predicted education:\n",
    "   $$\n",
    "   Y_i = \\beta_0 + \\beta_1 \\hat X_i + \\beta_2 W_i + \\varepsilon_i.\n",
    "   $$\n",
    "   Now $\\beta_1$ tells us: _‚ÄúIf schooling goes up for reasons **only** related to $Z$ (and not $U$), how much do earnings change?‚Äù_\n",
    "\n",
    "\n",
    "> **Caution:** In code, don‚Äôt literally run two separate OLS regressions and treat the fitted values as real data‚Äîalways use an IV/2SLS command, otherwise the standard errors will be wrong.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd3edbe",
   "metadata": {},
   "source": [
    "## 5. OLS vs IV in a simple simulation (ability / family background story)\n",
    "\n",
    "In this section, we build a **toy world** where we know the true effect of education on wages, and we deliberately introduce **ability/family background** as an omitted variable that creates *upward bias* in OLS.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "### 5.1 Data-generating story\n",
    "\n",
    "Each individual has:\n",
    "\n",
    "- `ability`: unobserved ability / family background  \n",
    "- `z`: an instrument (e.g. \"grew up near a college\"), taking values 0 or 1  \n",
    "- `educ`: years of schooling  \n",
    "- `wage`: log wage  \n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "We assume:\n",
    "\n",
    "1. **Education decision**\n",
    "\n",
    "$$\n",
    "\\text{educ}_i = 12 + 2 z_i + 1.0 \\cdot \\text{ability}_i + u_i\n",
    "$$\n",
    "\n",
    "- Baseline schooling is about 12 years.  \n",
    "- If $z_i = 1$ (near a college), schooling is about 2 years higher, on average.  \n",
    "- Higher ability ‚Üí more schooling.  \n",
    "- $u_i$ is just random noise.\n",
    "\n",
    "So schooling is **endogenous**: it depends on ability/family background, which the econometrician does *not* observe.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "2. **Wage equation (true model)**\n",
    "\n",
    "$$\n",
    "\\text{wage}_i = \\beta \\cdot \\text{educ}_i + \\gamma \\cdot \\text{ability}_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "- $\\beta = 0.10$: the **true causal return to education** is 10% higher wage per extra year (in log terms).  \n",
    "- $\\gamma > 0 \\; ( = 0.5)$: higher ability / better background raises wages.  \n",
    "- $\\varepsilon_i$ is random noise.\n",
    "\n",
    "In this world, ability affects both `educ` and `wage`, exactly the **omitted-variable** story we tell in class.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "3. **Instrument assumptions**\n",
    "\n",
    "We construct `z` so that:\n",
    "\n",
    "- It is **correlated** with education (people near a college study more).  \n",
    "- It is **independent** of ability and of the wage error term.\n",
    "\n",
    "So `z` satisfies:\n",
    "\n",
    "- **Relevance**: Cov($z$, `educ`) ‚â† 0  \n",
    "- **Exogeneity**: Cov($z$, error in wage equation) = 0  \n",
    "\n",
    "and is therefore a valid instrument in this simulation.\n",
    "\n",
    "<hr style=\"border: 1px dotted #bbb;\">\n",
    "\n",
    "### 5.2 Plan\n",
    "\n",
    "We will:\n",
    "\n",
    "1. **Simulate** the data according to this model.  \n",
    "2. Run **OLS** of `wage` on `educ` (ignoring ability).  \n",
    "3. Run **2SLS / IV**, using `z` as an instrument for `educ`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e649e0",
   "metadata": {},
   "source": [
    "## üì¶ Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dec47e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install -q numpy pandas statsmodels scipy matplotlib \n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
    "\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151c9709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True beta (return to education): 0.1\n",
      "\n",
      "First few rows of the simulated data:\n",
      "       wage       educ  z   ability\n",
      "0  2.617478  11.274131  0 -0.177377\n",
      "1  2.281824  13.605614  0  1.689619\n",
      "2  1.068528  10.248895  0 -0.727140\n",
      "3  0.637553  12.198370  0  1.083520\n",
      "4 -1.311154  10.372619  0 -1.634474\n"
     ]
    }
   ],
   "source": [
    "# Simulation: generate the data\n",
    "\n",
    "# Sample size\n",
    "n = 100000\n",
    "\n",
    "# Unobserved ability / family background\n",
    "ability = np.random.normal(size=n)\n",
    "\n",
    "# Instrument: z = 1 if \"near a college\", independent of ability\n",
    "z = np.random.binomial(1, 0.5, size=n)\n",
    "\n",
    "# Education decision (endogenous, depends on ability and z)\n",
    "u_educ = np.random.normal(size=n)\n",
    "educ = 12 + 2 * z + 1.0 * ability + u_educ   # observed education\n",
    "\n",
    "# Wage equation (true model)\n",
    "beta_true = 0.10   # true return to education\n",
    "gamma = 0.5        # effect of ability on wage\n",
    "eps = np.random.normal(size=n)\n",
    "\n",
    "wage = beta_true * educ + gamma * ability + eps\n",
    "\n",
    "# Put into a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"wage\": wage,\n",
    "    \"educ\": educ,\n",
    "    \"z\": z,\n",
    "    \"ability\": ability  # we won't use this in the regressions\n",
    "})\n",
    "\n",
    "print(\"True beta (return to education):\", beta_true)\n",
    "print(\"\\nFirst few rows of the simulated data:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca510c",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dotted #bbb;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecc5d3",
   "metadata": {},
   "source": [
    "### 5.3 Estimation: OLS vs manual 2SLS\n",
    "\n",
    "Now we estimate:\n",
    "\n",
    "1. **OLS** regression of `wage` on `educ`, ignoring ability.  \n",
    "2. **2SLS / IV** regression:\n",
    "\n",
    "   - First stage: regress `educ` on `z`.  \n",
    "   - Second stage: regress `wage` on the predicted values from the first stage.\n",
    "\n",
    "We implement 2SLS manually using `statsmodels`, without any additional IV packages, to keep everything transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c29e613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS results (wage ~ educ):\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.1974      0.026    -84.925      0.000      -2.248      -2.147\n",
      "educ           0.2691      0.002    136.270      0.000       0.265       0.273\n",
      "============================================================================== \n",
      "\n",
      "2SLS / IV results (wage ~ educ, instrumented by z):\n",
      "                          IV2SLS Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                   wage   R-squared:                       0.095\n",
      "Model:                         IV2SLS   Adj. R-squared:                  0.095\n",
      "Method:                     Two Stage   F-statistic:                     800.0\n",
      "                        Least Squares   Prob (F-statistic):          2.60e-175\n",
      "Date:                Fri, 14 Nov 2025                                         \n",
      "Time:                        04:01:08                                         \n",
      "No. Observations:              100000                                         \n",
      "Df Residuals:                   99998                                         \n",
      "Df Model:                           1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0084      0.046     -0.182      0.856      -0.099       0.082\n",
      "educ           0.1005      0.004     28.285      0.000       0.094       0.108\n",
      "==============================================================================\n",
      "Omnibus:                        0.227   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.893   Jarque-Bera (JB):                0.232\n",
      "Skew:                           0.003   Prob(JB):                        0.891\n",
      "Kurtosis:                       2.997   Cond. No.                         99.7\n",
      "============================================================================== \n",
      "\n",
      "Comparison of coefficients:\n",
      "  True beta       :  0.1000\n",
      "  OLS beta (educ) :  0.2691\n",
      "  2SLS beta       :  0.1005\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Estimation: OLS and 2SLS\n",
    "\n",
    "# OLS\n",
    "X_ols = sm.add_constant(df[\"educ\"])\n",
    "ols_res = sm.OLS(df[\"wage\"], X_ols).fit()\n",
    "\n",
    "print(\"OLS results (wage ~ educ):\")\n",
    "print(ols_res.summary().tables[1], \"\\n\")\n",
    "\n",
    "# 2SLS / IV: wage on educ, instrumented by z\n",
    "y = df[\"wage\"]\n",
    "X = sm.add_constant(df[\"educ\"])   # endogenous regressor(s) + constant\n",
    "Z = sm.add_constant(df[\"z\"])      # instruments + constant\n",
    "\n",
    "iv_res = IV2SLS(y, X, Z).fit()\n",
    "\n",
    "print(\"2SLS / IV results (wage ~ educ, instrumented by z):\")\n",
    "print(iv_res.summary(), \"\\n\")\n",
    "\n",
    "print(\"Comparison of coefficients:\")\n",
    "print(f\"  True beta       : {beta_true: .4f}\")\n",
    "print(f\"  OLS beta (educ) : {ols_res.params['educ']: .4f}\")\n",
    "print(f\"  2SLS beta       : {iv_res.params['educ']: .4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9107fbbf",
   "metadata": {},
   "source": [
    "<hr style=\"border: 1px dotted #bbb;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b1fab2",
   "metadata": {},
   "source": [
    "### 5.4 Interpreting the results\n",
    "\n",
    "From the simulation output, we expect to see:\n",
    "\n",
    "- **True causal effect** (by construction):\n",
    "\n",
    "  $$\n",
    "  \\beta = 0.10\n",
    "  $$\n",
    "\n",
    "- **OLS estimate** of the coefficient on `educ`:\n",
    "\n",
    "  $$\n",
    "  \\hat\\beta_{OLS} > 0.10\n",
    "  $$\n",
    "\n",
    "  OLS is **too large** because it mixes the effect of education with the effect of unobserved ability/family background.  \n",
    "  High-ability individuals both study more and earn more, so OLS attributes some of the ability effect to schooling.\n",
    "\n",
    "- **2SLS estimate** of the coefficient on `educ` (using `z` as the instrument):\n",
    "\n",
    "  $$\n",
    "  \\hat\\beta_{2SLS} \\approx 0.10\n",
    "  $$\n",
    "\n",
    "  2SLS uses only the variation in education coming from `z` (being near a college), which is independent of ability.  \n",
    "  In this idealized setup, it recovers a value close to the **true** causal effect and is therefore **smaller than the biased OLS estimate**.\n",
    "\n",
    "This simulation illustrates the classic **ability bias** story:\n",
    "\n",
    "> - When ability/family background is omitted and positively correlated with both education and wages, OLS overstates the return to education. \n",
    "> \n",
    "> - A valid instrument (here, `z`) allows 2SLS/IV to correct this bias and get closer to the true causal effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5c20b",
   "metadata": {},
   "source": [
    "---\n",
    "## References & Acknowledgments\n",
    "\n",
    "- This teaching material was prepared with the assistance of **OpenAI's ChatGPT (GPT-5)**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7e096",
   "metadata": {},
   "source": [
    "**End of lecture notebook.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
